{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Correlation and Pattern Prediction\n",
    "\n",
    "## Data Mining Techniques in Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem = pd.read_csv('task-and-exam-marks-in-groups.csv', delimiter=\";\", encoding=\"utf-8\")\n",
    "del gem[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tutor</th>\n",
       "      <th>team_id</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>hash2</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>punkte</th>\n",
       "      <th>note</th>\n",
       "      <th>student_id</th>\n",
       "      <th>pass</th>\n",
       "      <th>subject</th>\n",
       "      <th>semester</th>\n",
       "      <th>faculty</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tutor2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0afdc45f7ee8e52ebf1afb2970e37b36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tec</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tutor2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d821cd2c7b995d4e3a75c64d25e53529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tec</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tutor1</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>13.75</td>\n",
       "      <td>13.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fa873577b8543ed8a6d7d8d7fe6ca546</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tec</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tutor3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>e7c181a90d7161b4f885a69f6d426474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tec</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tutor5</td>\n",
       "      <td>5012.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>e2be9ece8b482afb4717e4e13907a525</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tec</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tutor  team_id     b1    b2    b3    b4    b5    b6    b7    b8    b9  \\\n",
       "0  tutor2      1.0  10.00   6.5  11.5  13.0   8.5   8.0  10.5  12.5   7.0   \n",
       "1  tutor2      1.0  10.00   6.5  11.5  13.0   8.5   8.0  10.5  12.5   7.0   \n",
       "2  tutor1   1146.0  13.75  13.5  14.5  13.5  11.0  11.5  13.5  15.0  14.5   \n",
       "3  tutor3     19.0  13.00   6.5   7.5   9.0   3.5   4.5   5.5   0.0   0.0   \n",
       "4  tutor5   5012.0  14.00  11.5  12.5  14.5   8.0   7.0  13.5   6.5   8.5   \n",
       "\n",
       "    b10  b11                             hash2   a1   a2   a3   a4   a5   a6  \\\n",
       "0  13.0  0.0  0afdc45f7ee8e52ebf1afb2970e37b36  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  13.0  0.0  d821cd2c7b995d4e3a75c64d25e53529  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2   4.0  0.0  fa873577b8543ed8a6d7d8d7fe6ca546  7.0  7.0  8.5  8.0  6.0  7.0   \n",
       "3   0.0  0.0  e7c181a90d7161b4f885a69f6d426474  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  14.0  0.0  e2be9ece8b482afb4717e4e13907a525  4.0  7.0  7.0  8.5  6.5  1.5   \n",
       "\n",
       "    a7  punkte  note  student_id  pass subject  semester faculty degree  \n",
       "0  0.0     0.0   0.0         0.0   0.0     inf       1.0     tec     ba  \n",
       "1  0.0     0.0   0.0         1.0   0.0     inf       1.0     tec     ba  \n",
       "2  8.5    52.0   3.3         2.0   1.0     inf       1.0     tec     ba  \n",
       "3  0.0     0.0   0.0         3.0   0.0     inf       1.0     tec     ba  \n",
       "4  4.0    38.5   5.0         4.0   0.0     inf       3.0     tec     ba  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of Dataset\n",
    "\n",
    "I have to separate the target or outcome variable from the independet explaining variables. Additionally, I throw out unnecessary columns like `student_id` as well as `note` and `punkte`, because they are too close related to the outcome variable. I also delete homework assignments 6 to 11, because I want to predict students pass/fail based on the information I have exact at the middle of the semester (predicting failure after 14 weeks maybe pretty easy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = gem.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    250.000000\n",
       "mean       0.412000\n",
       "std        0.493182\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: pass, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn[\"pass\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learn[\"b6\"]\n",
    "del learn[\"b7\"]\n",
    "del learn[\"b8\"]\n",
    "del learn[\"b9\"]\n",
    "del learn[\"b10\"]\n",
    "del learn[\"b11\"]\n",
    "del learn[\"hash2\"]\n",
    "del learn[\"a1\"]\n",
    "del learn[\"a2\"]\n",
    "del learn[\"a3\"]\n",
    "del learn[\"a4\"]\n",
    "del learn[\"a5\"]\n",
    "del learn[\"a6\"]\n",
    "del learn[\"a7\"]\n",
    "del learn[\"note\"]\n",
    "del learn[\"punkte\"]\n",
    "del learn[\"student_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = learn[\"pass\"]\n",
    "del learn[\"pass\"]\n",
    "del learn[\"team_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of Evaluation\n",
    "\n",
    "In the following code chunks I prepare the evaluation and comparison of different models: I want to have the information collected in a Confusion Matrix (= predictions and true values splitted up), additionally I print out the accuracy score and the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def confusion_matrix_report(y_true, y_pred):\n",
    "\tcm, labels = confusion_matrix(y_true, y_pred), unique_labels(y_true, y_pred)\n",
    "\tcolumn_width = max([len(str(x)) for x in labels] + [5])\n",
    "\treport = \" \" * column_width + \" \" + \"{:_^{}}\".format(\"Prediction\", column_width * len(labels))+ \"\\n\"\n",
    "\treport += \" \" * column_width + \" \".join([\"{:>{}}\".format(label, column_width) for label in labels]) + \"\\n\"\n",
    "\tfor i, label1 in enumerate(labels):\n",
    "\t\treport += \"{:>{}}\".format(label1, column_width) + \" \".join([\"{:{}d}\".format(cm[i, j], column_width) for j in range(len(labels))]) + \"\\n\"\n",
    "\treturn report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    prediction = model.predict(X_test)\n",
    "    y_pred = X_test.assign(prediction = prediction)\n",
    "    y_pred = y_pred.assign(true = y_test)\n",
    "    print(confusion_matrix_report(y_pred[\"true\"], y_pred[\"prediction\"]))\n",
    "    print(accuracy_score(y_pred[\"true\"], y_pred[\"prediction\"]))\n",
    "    print(classification_report(y_pred[\"true\"], y_pred[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The following code transforms categorical data step by step into dummy variables. \n",
    "\n",
    "+ `learn_subjects` includes the students study subjects\n",
    "+ `learn_faculty` summarizes the subject information in faculty dummies\n",
    "    + both include the `tutor` dummies\n",
    "+ `learn_only` focuses only on the first half of assignments, the semester and the anticipated degree\n",
    "\n",
    "We will see if these different coding levels affect the quality of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tutor', 'b1', 'b2', 'b3', 'b4', 'b5', 'subject', 'semester', 'faculty',\n",
       "       'degree'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>semester</th>\n",
       "      <th>tutor_tutor1</th>\n",
       "      <th>tutor_tutor2</th>\n",
       "      <th>tutor_tutor3</th>\n",
       "      <th>tutor_tutor4</th>\n",
       "      <th>tutor_tutor5</th>\n",
       "      <th>tutor_tutor6</th>\n",
       "      <th>subject_bwl</th>\n",
       "      <th>subject_inf</th>\n",
       "      <th>subject_lehr</th>\n",
       "      <th>subject_mat</th>\n",
       "      <th>subject_mkw</th>\n",
       "      <th>subject_mmm</th>\n",
       "      <th>subject_psy</th>\n",
       "      <th>subject_soz</th>\n",
       "      <th>subject_wip</th>\n",
       "      <th>degree_ba</th>\n",
       "      <th>degree_ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.75</td>\n",
       "      <td>13.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b1    b2    b3    b4   b5 semester  tutor_tutor1  tutor_tutor2  \\\n",
       "0     10   6.5  11.5    13  8.5        1             0             1   \n",
       "1     10   6.5  11.5    13  8.5        1             0             1   \n",
       "2  13.75  13.5  14.5  13.5   11        1             1             0   \n",
       "3     13   6.5   7.5     9  3.5        1             0             0   \n",
       "4     14  11.5  12.5  14.5    8        3             0             0   \n",
       "\n",
       "   tutor_tutor3  tutor_tutor4  tutor_tutor5  tutor_tutor6  subject_bwl  \\\n",
       "0             0             0             0             0            0   \n",
       "1             0             0             0             0            0   \n",
       "2             0             0             0             0            0   \n",
       "3             1             0             0             0            0   \n",
       "4             0             0             1             0            0   \n",
       "\n",
       "   subject_inf  subject_lehr  subject_mat  subject_mkw  subject_mmm  \\\n",
       "0            1             0            0            0            0   \n",
       "1            1             0            0            0            0   \n",
       "2            1             0            0            0            0   \n",
       "3            1             0            0            0            0   \n",
       "4            1             0            0            0            0   \n",
       "\n",
       "   subject_psy  subject_soz  subject_wip  degree_ba  degree_ma  \n",
       "0            0            0            0          1          0  \n",
       "1            0            0            0          1          0  \n",
       "2            0            0            0          1          0  \n",
       "3            0            0            0          1          0  \n",
       "4            0            0            0          1          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_subject = learn.copy()\n",
    "del learn_subject[\"faculty\"]\n",
    "learn_subject = pd.get_dummies(learn_subject)\n",
    "del learn_subject[\"subject_ext\"]\n",
    "del learn_subject[\"degree_ext\"]\n",
    "learn_subject = learn_subject.replace(np.nan, \"0\")\n",
    "learn_subject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>semester</th>\n",
       "      <th>tutor_tutor1</th>\n",
       "      <th>tutor_tutor2</th>\n",
       "      <th>tutor_tutor3</th>\n",
       "      <th>tutor_tutor4</th>\n",
       "      <th>tutor_tutor5</th>\n",
       "      <th>tutor_tutor6</th>\n",
       "      <th>faculty_eco</th>\n",
       "      <th>faculty_hum</th>\n",
       "      <th>faculty_soc</th>\n",
       "      <th>faculty_tec</th>\n",
       "      <th>degree_ba</th>\n",
       "      <th>degree_ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.75</td>\n",
       "      <td>13.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b1    b2    b3    b4   b5 semester  tutor_tutor1  tutor_tutor2  \\\n",
       "0     10   6.5  11.5    13  8.5        1             0             1   \n",
       "1     10   6.5  11.5    13  8.5        1             0             1   \n",
       "2  13.75  13.5  14.5  13.5   11        1             1             0   \n",
       "3     13   6.5   7.5     9  3.5        1             0             0   \n",
       "4     14  11.5  12.5  14.5    8        3             0             0   \n",
       "\n",
       "   tutor_tutor3  tutor_tutor4  tutor_tutor5  tutor_tutor6  faculty_eco  \\\n",
       "0             0             0             0             0            0   \n",
       "1             0             0             0             0            0   \n",
       "2             0             0             0             0            0   \n",
       "3             1             0             0             0            0   \n",
       "4             0             0             1             0            0   \n",
       "\n",
       "   faculty_hum  faculty_soc  faculty_tec  degree_ba  degree_ma  \n",
       "0            0            0            1          1          0  \n",
       "1            0            0            1          1          0  \n",
       "2            0            0            1          1          0  \n",
       "3            0            0            1          1          0  \n",
       "4            0            0            1          1          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_faculty = learn.copy()\n",
    "del learn_faculty[\"subject\"]\n",
    "learn_faculty = pd.get_dummies(learn_faculty)\n",
    "del learn_faculty[\"faculty_ext\"]\n",
    "del learn_faculty[\"degree_ext\"]\n",
    "learn_faculty = learn_faculty.replace(np.nan, \"0\")\n",
    "learn_faculty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>semester</th>\n",
       "      <th>degree_ba</th>\n",
       "      <th>degree_ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.75</td>\n",
       "      <td>13.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b1    b2    b3    b4   b5 semester  degree_ba  degree_ma\n",
       "0     10   6.5  11.5    13  8.5        1          1          0\n",
       "1     10   6.5  11.5    13  8.5        1          1          0\n",
       "2  13.75  13.5  14.5  13.5   11        1          1          0\n",
       "3     13   6.5   7.5     9  3.5        1          1          0\n",
       "4     14  11.5  12.5  14.5    8        3          1          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_only = learn.copy()\n",
    "del learn_only[\"faculty\"]\n",
    "del learn_only[\"tutor\"]\n",
    "del learn_only[\"subject\"]\n",
    "learn_only = pd.get_dummies(learn_only)\n",
    "del learn_only[\"degree_ext\"]\n",
    "learn_only = learn_only.replace(np.nan, \"0\")\n",
    "learn_only.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we split the three datasets into train and test datasets.\n",
    "\n",
    "+ `learn_subject` becomes to `X_train`, `X_test`, `y_train` and `y_test`\n",
    "+ `learn_faculty` becomes to `X_train2`, etc.\n",
    "+ `learn_only` becomes to `X_train3`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 8) (212,)\n",
      "(38, 8) (38,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(learn_subject, target, test_size=0.15, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(learn_faculty, target, test_size=0.15, random_state=42)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(learn_only, target, test_size=0.15, random_state=42)\n",
    "print(X_train3.shape, y_train3.shape)\n",
    "print(X_test3.shape, y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    212.000000\n",
       "mean       0.415094\n",
       "std        0.493905\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: pass, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (as Baseline Model)\n",
    "\n",
    "Naive Bayes usually is the simplest and weakest algorithm, to it works as \"baseline\" which has to be topped by the other algorithms. The baseline accuracy is about `0.58`, just as the baseline F1. Note here, `0.58` is just as good as guessing \"failed\" for every student, beacuse this is how pass/fail are distributed in the data set. We can do much better!\n",
    "\n",
    "The model gets better when we use the `faculty` dataset, accuracy and F1 increase to `0.63`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   12    11\n",
      "  1.0    5    10\n",
      "\n",
      "0.578947368421\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.52      0.60        23\n",
      "        1.0       0.48      0.67      0.56        15\n",
      "\n",
      "avg / total       0.62      0.58      0.58        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(naive_bayes, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   11    12\n",
      "  1.0    2    13\n",
      "\n",
      "0.631578947368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.48      0.61        23\n",
      "        1.0       0.52      0.87      0.65        15\n",
      "\n",
      "avg / total       0.72      0.63      0.63        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train2, y_train2)\n",
    "evaluate(naive_bayes, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   11    12\n",
      "  1.0    3    12\n",
      "\n",
      "0.605263157895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.48      0.59        23\n",
      "        1.0       0.50      0.80      0.62        15\n",
      "\n",
      "avg / total       0.67      0.61      0.60        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train3, y_train3)\n",
    "evaluate(naive_bayes, X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "When I created dummy variables beforehand, I now excluded one category each from the calculation, because these variables would correlate perfectly and this would disturb the logistic regression algorithm. Reference categories are `tutor fred`, `subject mkw`, `degree ma` and `faculty rom`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train[X_train.columns.difference(['tutor_fred', 'subject_mkw', 'degree_ma'])], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   16     7\n",
      "  1.0    7     8\n",
      "\n",
      "0.631578947368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.70      0.70        23\n",
      "        1.0       0.53      0.53      0.53        15\n",
      "\n",
      "avg / total       0.63      0.63      0.63        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, X_test[X_test.columns.difference(['tutor_fred', 'subject_mkw', 'degree_ma'])], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1</td>\n",
       "      <td>[-0.0354970356237]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2</td>\n",
       "      <td>[0.139187157544]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b3</td>\n",
       "      <td>[-0.00999267603413]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b4</td>\n",
       "      <td>[0.0758918461247]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b5</td>\n",
       "      <td>[0.00967320179782]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>degree_ba</td>\n",
       "      <td>[0.969493832111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>semester</td>\n",
       "      <td>[-0.167625722114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>subject_bwl</td>\n",
       "      <td>[-0.162641094707]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subject_inf</td>\n",
       "      <td>[0.122893743997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>subject_lehr</td>\n",
       "      <td>[0.276920627336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>subject_mat</td>\n",
       "      <td>[1.29557563867]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>subject_mmm</td>\n",
       "      <td>[1.28538263318]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>subject_psy</td>\n",
       "      <td>[0.33259652233]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>subject_soz</td>\n",
       "      <td>[0.335565828922]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>subject_wip</td>\n",
       "      <td>[-0.0858070271977]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tutor_tutor1</td>\n",
       "      <td>[-0.463490030916]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tutor_tutor2</td>\n",
       "      <td>[-0.775978862319]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tutor_tutor3</td>\n",
       "      <td>[-0.445264772398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tutor_tutor4</td>\n",
       "      <td>[-0.836198286702]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tutor_tutor5</td>\n",
       "      <td>[-0.131393186069]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tutor_tutor6</td>\n",
       "      <td>[-0.214110737304]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                    1\n",
       "0             b1   [-0.0354970356237]\n",
       "1             b2     [0.139187157544]\n",
       "2             b3  [-0.00999267603413]\n",
       "3             b4    [0.0758918461247]\n",
       "4             b5   [0.00967320179782]\n",
       "5      degree_ba     [0.969493832111]\n",
       "6       semester    [-0.167625722114]\n",
       "7    subject_bwl    [-0.162641094707]\n",
       "8    subject_inf     [0.122893743997]\n",
       "9   subject_lehr     [0.276920627336]\n",
       "10   subject_mat      [1.29557563867]\n",
       "11   subject_mmm      [1.28538263318]\n",
       "12   subject_psy      [0.33259652233]\n",
       "13   subject_soz     [0.335565828922]\n",
       "14   subject_wip   [-0.0858070271977]\n",
       "15  tutor_tutor1    [-0.463490030916]\n",
       "16  tutor_tutor2    [-0.775978862319]\n",
       "17  tutor_tutor3    [-0.445264772398]\n",
       "18  tutor_tutor4    [-0.836198286702]\n",
       "19  tutor_tutor5    [-0.131393186069]\n",
       "20  tutor_tutor6    [-0.214110737304]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(X_test.columns.difference(['tutor_fred', 'subject_mkw', 'degree_ma']), np.transpose(model.coef_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with small(er) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train2[X_train2.columns.difference(['tutor_fred', 'faculty_rom', 'degree_ma'])], y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   15     8\n",
      "  1.0    6     9\n",
      "\n",
      "0.631578947368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.65      0.68        23\n",
      "        1.0       0.53      0.60      0.56        15\n",
      "\n",
      "avg / total       0.64      0.63      0.63        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model2, X_test2[X_test2.columns.difference(['tutor_fred', 'faculty_rom', 'degree_ma'])], y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1</td>\n",
       "      <td>[-0.0330077892786]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2</td>\n",
       "      <td>[0.134181471845]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b3</td>\n",
       "      <td>[0.000728653754542]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b4</td>\n",
       "      <td>[0.0698819379776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b5</td>\n",
       "      <td>[0.0120806566165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>degree_ba</td>\n",
       "      <td>[0.0704938519207]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faculty_eco</td>\n",
       "      <td>[0.494810453776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>faculty_hum</td>\n",
       "      <td>[0.817308555716]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>faculty_soc</td>\n",
       "      <td>[0.554133877749]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>faculty_tec</td>\n",
       "      <td>[1.12982266554]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>semester</td>\n",
       "      <td>[-0.0325825616704]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tutor_tutor1</td>\n",
       "      <td>[-0.46642183203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tutor_tutor2</td>\n",
       "      <td>[-0.703485749886]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tutor_tutor3</td>\n",
       "      <td>[-0.430612560002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tutor_tutor4</td>\n",
       "      <td>[-0.960170222609]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tutor_tutor5</td>\n",
       "      <td>[-0.120187560794]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tutor_tutor6</td>\n",
       "      <td>[-0.204037190959]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                    1\n",
       "0             b1   [-0.0330077892786]\n",
       "1             b2     [0.134181471845]\n",
       "2             b3  [0.000728653754542]\n",
       "3             b4    [0.0698819379776]\n",
       "4             b5    [0.0120806566165]\n",
       "5      degree_ba    [0.0704938519207]\n",
       "6    faculty_eco     [0.494810453776]\n",
       "7    faculty_hum     [0.817308555716]\n",
       "8    faculty_soc     [0.554133877749]\n",
       "9    faculty_tec      [1.12982266554]\n",
       "10      semester   [-0.0325825616704]\n",
       "11  tutor_tutor1     [-0.46642183203]\n",
       "12  tutor_tutor2    [-0.703485749886]\n",
       "13  tutor_tutor3    [-0.430612560002]\n",
       "14  tutor_tutor4    [-0.960170222609]\n",
       "15  tutor_tutor5    [-0.120187560794]\n",
       "16  tutor_tutor6    [-0.204037190959]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(X_train2.columns.difference(['tutor_fred', 'faculty_rom', 'degree_ma']), np.transpose(model2.coef_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only with Homeworks and Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LogisticRegression()\n",
    "model3.fit(X_train3[X_train3.columns.difference(['degree_ma'])], y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   19     4\n",
      "  1.0    7     8\n",
      "\n",
      "0.710526315789\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.83      0.78        23\n",
      "        1.0       0.67      0.53      0.59        15\n",
      "\n",
      "avg / total       0.71      0.71      0.70        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model3, X_test3[X_test3.columns.difference(['degree_ma'])], y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1</td>\n",
       "      <td>[-0.044915583164]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2</td>\n",
       "      <td>[0.105799911051]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b3</td>\n",
       "      <td>[0.022057651665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b4</td>\n",
       "      <td>[0.0620458060452]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b5</td>\n",
       "      <td>[0.0214488502108]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>degree_ba</td>\n",
       "      <td>[0.836633856403]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>semester</td>\n",
       "      <td>[-0.0333338886549]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                   1\n",
       "0         b1   [-0.044915583164]\n",
       "1         b2    [0.105799911051]\n",
       "2         b3    [0.022057651665]\n",
       "3         b4   [0.0620458060452]\n",
       "4         b5   [0.0214488502108]\n",
       "5  degree_ba    [0.836633856403]\n",
       "6   semester  [-0.0333338886549]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(X_train3.columns.difference(['degree_ma']), np.transpose(model3.coef_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this model with the smallest tested dataset seems to deliver the best results for Logistic Regression, it also topps the best model from Naive Bayes. We get a result of `0.70` F1 and `0.71` Accuracy, which is better than before, but still not quite good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the Decision Tree can be optimized with a bunch of parameters, we have to test for a lot more options (node sizes and depths). \n",
    "On unseen, we see that a tree with 11 nodes happens to be the best, so we choose depth 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cross_val = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "acc_each_split = cross_val_score(decision_tree, learn_subject, target, cv=cross_val, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for depth in [1,2,3,4,5,6,7,8,9]:    \n",
    "#\tdecision_tree = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "#\tcross_val = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#\tacc_each_split = cross_val_score(decision_tree, learn_subject, target, cv=cross_val, scoring='accuracy')\n",
    "#\tdecision_tree.fit(X_train, y_train)\n",
    "#\tprint(\"tree with depth= {} and {} nodes has accuracy {}\".format(depth, decision_tree.tree_.node_count,acc_each_split.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose 3\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   23     0\n",
      "  1.0   12     3\n",
      "\n",
      "0.684210526316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.66      1.00      0.79        23\n",
      "        1.0       1.00      0.20      0.33        15\n",
      "\n",
      "avg / total       0.79      0.68      0.61        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(decision_tree, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.425320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5</th>\n",
       "      <td>0.265848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semester</th>\n",
       "      <td>0.284679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor1</th>\n",
       "      <td>0.024152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_bwl</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_inf</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_lehr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_mat</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_mkw</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_mmm</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_psy</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_soz</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_wip</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ba</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ma</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Importance\n",
       "b1              0.000000\n",
       "b2              0.425320\n",
       "b3              0.000000\n",
       "b4              0.000000\n",
       "b5              0.265848\n",
       "semester        0.284679\n",
       "tutor_tutor1    0.024152\n",
       "tutor_tutor2    0.000000\n",
       "tutor_tutor3    0.000000\n",
       "tutor_tutor4    0.000000\n",
       "tutor_tutor5    0.000000\n",
       "tutor_tutor6    0.000000\n",
       "subject_bwl     0.000000\n",
       "subject_inf     0.000000\n",
       "subject_lehr    0.000000\n",
       "subject_mat     0.000000\n",
       "subject_mkw     0.000000\n",
       "subject_mmm     0.000000\n",
       "subject_psy     0.000000\n",
       "subject_soz     0.000000\n",
       "subject_wip     0.000000\n",
       "degree_ba       0.000000\n",
       "degree_ma       0.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance =  decision_tree.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=X_train.columns, \n",
    "                          columns=[\"Importance\"])\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, only homework assignment 2 and 5, as well as the semester count and one of the tutors happen to be relevant splitting criterion variables for the branches of the tree. Sure, with depth = 3 there is not much place for more than 4 splittings, but the selection of variables is still striking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on small(er) Data\n",
    "\n",
    "Training and testing on smaller data requires a new depth evaluation and this time a depth of 4 with 17 nodes is evaluated as the best model. On unseen data, it gaines Accuracy as well as F1 of `0.71`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for depth in [1,2,3,4,5,6,7,8,9]:    \n",
    "# \tdecision_tree = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "# \tcross_val = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# \tacc_each_split = cross_val_score(decision_tree, X_train2, y_train2, cv=cross_val, scoring='accuracy')\n",
    "# \tdecision_tree.fit(X_train2, y_train2)\n",
    "# \tprint(\"tree with depth= {} and {} nodes has accuracy {}\".format(depth, decision_tree.tree_.node_count,acc_each_split.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose 4\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=4)\n",
    "decision_tree.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   15     8\n",
      "  1.0    3    12\n",
      "\n",
      "0.710526315789\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.65      0.73        23\n",
      "        1.0       0.60      0.80      0.69        15\n",
      "\n",
      "avg / total       0.74      0.71      0.71        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(decision_tree, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.358653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3</th>\n",
       "      <td>0.121164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4</th>\n",
       "      <td>0.016450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5</th>\n",
       "      <td>0.224178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semester</th>\n",
       "      <td>0.259189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor1</th>\n",
       "      <td>0.020367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faculty_eco</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faculty_hum</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faculty_soc</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faculty_tec</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ba</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ma</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Importance\n",
       "b1              0.000000\n",
       "b2              0.358653\n",
       "b3              0.121164\n",
       "b4              0.016450\n",
       "b5              0.224178\n",
       "semester        0.259189\n",
       "tutor_tutor1    0.020367\n",
       "tutor_tutor2    0.000000\n",
       "tutor_tutor3    0.000000\n",
       "tutor_tutor4    0.000000\n",
       "tutor_tutor5    0.000000\n",
       "tutor_tutor6    0.000000\n",
       "faculty_eco     0.000000\n",
       "faculty_hum     0.000000\n",
       "faculty_soc     0.000000\n",
       "faculty_tec     0.000000\n",
       "degree_ba       0.000000\n",
       "degree_ma       0.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance =  decision_tree.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=X_train2.columns, \n",
    "                          columns=[\"Importance\"])\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that more than 4 variables are used, namely two other homework assignments were also taken to do the branch splitting. The theory seems to work that the assignments say much about the result at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Homework and Semester Data only\n",
    "\n",
    "Same procedure as for the last step, depth of 4 remains the best. Accuracy and F1 do not change for this smaller data set, nor does the selection of important variables for the splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for depth in [1,2,3,4,5,6,7,8,9]:    \n",
    "# \tdecision_tree = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "# \tcross_val = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# \tacc_each_split = cross_val_score(decision_tree, X_train3, y_train3, cv=cross_val, scoring='accuracy')\n",
    "# \tdecision_tree.fit(X_train3, y_train3)\n",
    "# \tprint(\"tree with depth= {} and {} nodes has accuracy {}\".format(depth, decision_tree.tree_.node_count,acc_each_split.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose 4\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=4)\n",
    "decision_tree.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   15     8\n",
      "  1.0    3    12\n",
      "\n",
      "0.710526315789\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.65      0.73        23\n",
      "        1.0       0.60      0.80      0.69        15\n",
      "\n",
      "avg / total       0.74      0.71      0.71        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(decision_tree, X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.340095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3</th>\n",
       "      <td>0.117743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4</th>\n",
       "      <td>0.015985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5</th>\n",
       "      <td>0.251150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semester</th>\n",
       "      <td>0.262949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ba</th>\n",
       "      <td>0.012078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ma</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Importance\n",
       "b1           0.000000\n",
       "b2           0.340095\n",
       "b3           0.117743\n",
       "b4           0.015985\n",
       "b5           0.251150\n",
       "semester     0.262949\n",
       "degree_ba    0.012078\n",
       "degree_ma    0.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance =  decision_tree.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=X_train3.columns, \n",
    "                          columns=[\"Importance\"])\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "A Random Forest creates several decision trees and combines the predictions of them. Again, I try to optimize depth and number of estimators (= number of generated trees), before testing the model on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for estimators in [10, 20, 30, 40, 50, 60]:\n",
    "#     for depth in [1,2,3,4,5,6,7,8,9]:    \n",
    "#         rf_model =  RandomForestClassifier(max_depth=depth, n_estimators=estimators)\n",
    "#         cross_val = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#         acc_each_split = cross_val_score(rf_model, X_train3, y_train3, cv=cross_val, scoring='accuracy')\n",
    "#         rf_model.fit(X_train, y_train)\n",
    "#         print(\"tree with depth= {} and estimators= {} has accuracy {}\".format(depth, estimators, acc_each_split.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   16     7\n",
      "  1.0    2    13\n",
      "\n",
      "0.763157894737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.70      0.78        23\n",
      "        1.0       0.65      0.87      0.74        15\n",
      "\n",
      "avg / total       0.79      0.76      0.77        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model =  RandomForestClassifier(max_depth=8,n_estimators=40,random_state=42)\n",
    "rf_model.fit(X_train,y_train)\n",
    "evaluate(rf_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.096457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.150179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3</th>\n",
       "      <td>0.144312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4</th>\n",
       "      <td>0.112659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5</th>\n",
       "      <td>0.108465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semester</th>\n",
       "      <td>0.152069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor1</th>\n",
       "      <td>0.017121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor2</th>\n",
       "      <td>0.009375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor3</th>\n",
       "      <td>0.010474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor4</th>\n",
       "      <td>0.014031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor5</th>\n",
       "      <td>0.013541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor6</th>\n",
       "      <td>0.018775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_bwl</th>\n",
       "      <td>0.001088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_inf</th>\n",
       "      <td>0.026165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_lehr</th>\n",
       "      <td>0.008265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_mat</th>\n",
       "      <td>0.034344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_mkw</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_mmm</th>\n",
       "      <td>0.016655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_psy</th>\n",
       "      <td>0.004053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_soz</th>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_wip</th>\n",
       "      <td>0.018992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ba</th>\n",
       "      <td>0.033258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ma</th>\n",
       "      <td>0.008474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Importance\n",
       "b1              0.096457\n",
       "b2              0.150179\n",
       "b3              0.144312\n",
       "b4              0.112659\n",
       "b5              0.108465\n",
       "semester        0.152069\n",
       "tutor_tutor1    0.017121\n",
       "tutor_tutor2    0.009375\n",
       "tutor_tutor3    0.010474\n",
       "tutor_tutor4    0.014031\n",
       "tutor_tutor5    0.013541\n",
       "tutor_tutor6    0.018775\n",
       "subject_bwl     0.001088\n",
       "subject_inf     0.026165\n",
       "subject_lehr    0.008265\n",
       "subject_mat     0.034344\n",
       "subject_mkw     0.000000\n",
       "subject_mmm     0.016655\n",
       "subject_psy     0.004053\n",
       "subject_soz     0.001248\n",
       "subject_wip     0.018992\n",
       "degree_ba       0.033258\n",
       "degree_ma       0.008474"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance =  rf_model.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=X_train.columns, \n",
    "                          columns=[\"Importance\"])\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for estimators in [10, 20, 30, 40, 50, 60]:\n",
    "#     for depth in [1,2,3,4,5,6,7,8,9]:    \n",
    "#         rf_model2 =  RandomForestClassifier(max_depth=depth, n_estimators=estimators)\n",
    "#         cross_val = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#         acc_each_split = cross_val_score(rf_model2, X_train2, y_train2, cv=cross_val, scoring='accuracy')\n",
    "#         rf_model.fit(X_train2, y_train2)\n",
    "#         print(\"tree with depth= {} and estimators= {} has accuracy {}\".format(depth, estimators, acc_each_split.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   17     6\n",
      "  1.0    2    13\n",
      "\n",
      "0.789473684211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.74      0.81        23\n",
      "        1.0       0.68      0.87      0.76        15\n",
      "\n",
      "avg / total       0.81      0.79      0.79        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model2 =  RandomForestClassifier(max_depth=8,n_estimators=30,random_state=42)\n",
    "rf_model2.fit(X_train2, y_train2)\n",
    "evaluate(rf_model2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.100466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.138363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3</th>\n",
       "      <td>0.139027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4</th>\n",
       "      <td>0.114024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5</th>\n",
       "      <td>0.132201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semester</th>\n",
       "      <td>0.180162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor1</th>\n",
       "      <td>0.009988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor2</th>\n",
       "      <td>0.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor3</th>\n",
       "      <td>0.016512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor4</th>\n",
       "      <td>0.019385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor5</th>\n",
       "      <td>0.014470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutor_tutor6</th>\n",
       "      <td>0.019599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faculty_eco</th>\n",
       "      <td>0.015868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faculty_hum</th>\n",
       "      <td>0.007861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faculty_soc</th>\n",
       "      <td>0.005177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faculty_tec</th>\n",
       "      <td>0.028415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ba</th>\n",
       "      <td>0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ma</th>\n",
       "      <td>0.017281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Importance\n",
       "b1              0.100466\n",
       "b2              0.138363\n",
       "b3              0.139027\n",
       "b4              0.114024\n",
       "b5              0.132201\n",
       "semester        0.180162\n",
       "tutor_tutor1    0.009988\n",
       "tutor_tutor2    0.008155\n",
       "tutor_tutor3    0.016512\n",
       "tutor_tutor4    0.019385\n",
       "tutor_tutor5    0.014470\n",
       "tutor_tutor6    0.019599\n",
       "faculty_eco     0.015868\n",
       "faculty_hum     0.007861\n",
       "faculty_soc     0.005177\n",
       "faculty_tec     0.028415\n",
       "degree_ba       0.033046\n",
       "degree_ma       0.017281"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance =  rf_model2.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=X_train2.columns, \n",
    "                          columns=[\"Importance\"])\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for estimators in [10, 20, 30, 40, 50, 60]:\n",
    "#     for depth in [1,2,3,4,5,6,7,8,9]:    \n",
    "#         rf_model3 =  RandomForestClassifier(max_depth=depth, n_estimators=estimators)\n",
    "#         cross_val = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#         acc_each_split = cross_val_score(rf_model3, X_train3, y_train3, cv=cross_val, scoring='accuracy')\n",
    "#         rf_model.fit(X_train3, y_train3)\n",
    "#         print(\"tree with depth= {} and estimators= {} has accuracy {}\".format(depth, estimators, acc_each_split.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction\n",
      "       0.0   1.0\n",
      "  0.0   17     6\n",
      "  1.0    2    13\n",
      "\n",
      "0.789473684211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.74      0.81        23\n",
      "        1.0       0.68      0.87      0.76        15\n",
      "\n",
      "avg / total       0.81      0.79      0.79        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model3 =  RandomForestClassifier(max_depth=9,n_estimators=50, random_state=42)\n",
    "rf_model3.fit(X_train3,y_train3)\n",
    "evaluate(rf_model3, X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.111249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.153621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3</th>\n",
       "      <td>0.169878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4</th>\n",
       "      <td>0.161381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5</th>\n",
       "      <td>0.148955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semester</th>\n",
       "      <td>0.191951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ba</th>\n",
       "      <td>0.041144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_ma</th>\n",
       "      <td>0.021821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Importance\n",
       "b1           0.111249\n",
       "b2           0.153621\n",
       "b3           0.169878\n",
       "b4           0.161381\n",
       "b5           0.148955\n",
       "semester     0.191951\n",
       "degree_ba    0.041144\n",
       "degree_ma    0.021821"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance =  rf_model3.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=X_train3.columns, \n",
    "                          columns=[\"Importance\"])\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata = pd.Series(range(0,160,1))\n",
    "plotdata = plotdata.to_frame(\"weight\")\n",
    "plotdata[\"precision\"] = 0\n",
    "plotdata[\"recall\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\laris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\laris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\laris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "for i in plotdata[\"weight\"]:\n",
    "    rf_model =  RandomForestClassifier(max_depth = 8, \n",
    "                                       n_estimators = 20, \n",
    "                                       class_weight = {0:i, 1:1}, \n",
    "                                       random_state = 42)\n",
    "    rf_model.fit(X_train3,y_train3)\n",
    "    #evaluate(rf_model, X_test3, y_test3)\n",
    "    prediction = rf_model.predict(X_test3)\n",
    "    y_pred = X_test3.assign(prediction = prediction)\n",
    "    y_pred = y_pred.assign(true = y_test3)\n",
    "    plotdata[\"recall\"][plotdata[\"weight\"] == i] = confusion_matrix(y_pred[\"true\"], y_pred[\"prediction\"])[0,0] / (confusion_matrix(y_pred[\"true\"], y_pred[\"prediction\"])[0,0] + confusion_matrix(y_pred[\"true\"], y_pred[\"prediction\"])[0,1])\n",
    "    plotdata[\"precision\"][plotdata[\"weight\"] == i] = confusion_matrix(y_pred[\"true\"], y_pred[\"prediction\"])[0,0] / (confusion_matrix(y_pred[\"true\"], y_pred[\"prediction\"])[0,0] + confusion_matrix(y_pred[\"true\"], y_pred[\"prediction\"])[1,0])\n",
    "    #print(row['weight'], row['precision'], row['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAETCAYAAAArjI32AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4XGXZx/HvJGnTJWlJaboA3aD0ZiuLLXtZRBZF4EVFUUD2XVQUEETcAAF9QRQRQRaLG4pKZSuyyqtsyiot0FtK9wIlXdKmTZs2mXn/eM4kk5nsmSRzyu9zXb2amTNz5p6TyW+euc+Z5yRSqRQiIhJfRX1dgIiIdI+CXEQk5hTkIiIxpyAXEYk5BbmISMwpyEVEYq6krwsoBGY2HngHmBVdVQRsAn7q7r+ObnMlMNfdf21mpwJXAm8BZwKPAA3Aue7+fA/Xejtwq7u/3MKyEuBS4EQgfVzp08C33X1lT9bV08wsBVQC+wGHuvtX8rTeBUAdsJ6wzUqBJHCxu/+tnft+Etjb3b+Tj1raeJwxtPIaM7PpwGFAVdbdjnT3d9tY52vAwcCxwHHufpSZ3QH8wd2fyFPdpwJfJuRMCfA8cJG7rzazCcD17v6ZTq7zYmAXdz+1izUNBWa4+yFduX+hUpA3We/uu6cvmNk44EkzW+fuf8n6Yz0ZuNzdf2tmJwPvu/uhvVTnYcBtrSz7A7ARmObuK82sH/A14Hkzm+ruNb1UY49x9weAB/K82hPd/aX0BTM7DvgVMLqd++0JDMtzLS35KG2/xm509+s7s8L0a93MMq87s8sVZjGzPYHvAFOj12Ix8HPgF8AJwDjA2lhFT6kA9uqDx+1RCvJWuPtCM/sOcAnwl2jkMxvYmvBCmGBmlYSgHGpmf3f3j5rZ0cAVQH+gljCye97MvgfsSwiH1939JDP7FvAZwieABcD57v6umT1NGL3sD4wF/gmcAlwFbAX8zsxOdvd/pes1s32BfYDx7l4fPYdNwI/MbH/gXDNbDRzj7kdF99kBeDJ6jEnAT4EtgWLgJne/y8wOjq5fBwwGDgTuALYnjFxfBs6JyrgxqqEcSABnuvuz0bZbTwi+UcC9hBHk0dHlM939qeh2KWBHwuj7MeAr0fNIP89TaRpBtrid3D0Z3e6y6HGfAr7q7u2+3s0sAUwAVkaXBxPCZxIhtGsIQbQFcC5QbGar3f1bZnYGcD7h97kCuMDd55jZNODH0XZNAde6+19aeOyzga8QRt7LgAsIr7eryXiNtfccMtY3iRCeZYTXzWvA8e6+IeMTTubtnwZuBl4ivC5mAntHz/tb7v5HMxsE3Er4PVcDbwK0MEIeHW2HQcBKd2+I/p52jkL9DmBrM3uU8PqZ7e5lUR3j05ejwchNhAHMB9F2WR3dbijhtTkZ6BfVfIm715vZBuC66H5bET5d/4TwBj0w+kQyhfBm8ynCAGgFcKq7v9fRbVwo1CNv238IL5JG7v41wgv9Ene/kfBC+GcU4tsD1xA+1u4BnA3cF4UBhFHIR6IQPzla917R6Ggm4cWdth3ho+9k4BDgIHf/FvAuYQT5L5rbD3g+HeJZngCmAfcA08xsVHT9aYQXdgL4M3CZu08BDgIuNrN9otvtAnzB3XcDjgHKo5r3jJZvS/iD3wrY1913Au4mBGnaHoQ3sqmEN7+17r4f4Q8x83a7AYcCO0X/zqFtOdvJzHYCfkhowewBrCGEaGt+Z2avmdliYDGwA+FNBuATQLW77+Puk4AXCQH9L0Kg/TEK8YMIb7YHRI/5I+C+aB3fB34cbdvTozqbMbNDgG8AH4228++BvxJaY42vsVbq/1pUf/pfemR9FnC3u+8LTCS8QX2yje2QaVvgUXffi9Cu+1F0/bcJA8AdCL+nPVq5/yPAs8ACM3vFzG4mvF6edvcGQkvyHXc/op06zie8ie5ECOWxGctuBF6OtusewHDg69GyUmC5u+8PHAdcZ2YDCK/59KfvrYALgT3dfSph4LB3O/UUJI3I25YijKo76jDCSOTJjI+sScIfEcALGUF7FGFk/1J022LC6CXtQXdPAjVmNpeOfYTv18r1pUDK3WvM7M/ASWZ2I3ASIeAnEQLxroy6BxL+ON4CFrv7wuj6Z4BrotHb48BP3H0uMNfMrgDOMbN0uGa2ch6MRtbvm9k6IN1/fifruU1397UAZvZrQg/35jaec0vbaXfgMXdfEt3mZ8D32ljHie7+UtS3fQJ4y93nAbj7n81snpl9mfB7PJjwKSDbJ6Plz2Vsw2FmNozwCeTn0ae1J4DLW7j/xwlvClXR4043s58C49uoO6211sqlwGFm9g3C73grwui8IzYRBhcAr9D0OzoS+Hq0zdeY2d3Artl3jn7XJ5rZJYTW0EGEN/cngeM7WAOEN4vfu/tGYKOZ/S7j8Y4C9oo+CUF4zWa6P6P+UsInykxLCYO1V8zsEeARd3+yE7UVDI3I27YnTTtAO6IYeNLdd0//I3wEnR0tX5t12x9m3G4qoUWQtj7j5xRh1NyWZwkv6kEtLPso8Fz08x2EHv/HgTfdfX5US3ULdf8qu+7o9hOBa4EhwBNmdly04+/h6Gb3E0armTXXZdW0iZZlfqIoIrQZ2tLSdqrPeuz21gE0PrcvAtea2d4AZnYecCfhDf33hE81Lf0uioHfZGy/jxB+p6vc/TbCJ4bHgSOA16O2QKaW/hYTtP7m3BH3ED4VLiSMXl9ppfaWbIzCGpq//jq0bc3sdDM7xt3fdfffufvZhG3yWTMbnnXz7Nd3/zaWZb4+ioHPZmzzvQntqLT1AO6e3vHf7LlHz+8g4FRCW+XG6M0zdhTkrYj6i98GbujE3Z4CDo96z5jZkcDrwIAWbvsocKaZDYkuXwn8pgOPUU8Lf9zu/gLwf8B0M6uIHr846sNPItpBGt0uQfi4fnv67sAGMzsput8YwpvPlOzHiYLtV4QR76XR89iF8GnkQXf/BaH9cCxttzNac7yZlUYfg08BHuzCOh4FDjWzraPLHd6J5+7PAdOBW8ysiBC80939TsJ2Opqm55X5u3gM+IKZpXeQnksYfWJmzwF7uPt0QrBuQdjpll3z8dF+F8zsNEK4zO1o7S04ArjS3f9ICMS96drvJNPDwGlmVhQNGk6g6QipTEngh2a2TcZ1kwj7glbRfNtVA/2jlhiEnnXa34CTzWxA9JrIHM0/SmgrJcyslLATPDPIW1JP2K+RMLPdCK/zt9z9WsKb3W7t3L8gKcibDMzoMb5C+GP+prs/3M79Grn7G4Q/1D+Y2X8IOyePcfd1Ldz8DuAh4AUze4PwcfHUDjzMX4E/mtnhLSw7iRCi/2dmswhtkTHAfu6+OuN2txN6oH+N6t4I/A/hjeV1Qih9292fbeExfk0IgzfN7CXCqPynhBH4QdH9nye0TCZEYdgZtYSdlrOi/3/V9s1zuft/CX34R6Mad6RzLbJvEloaZwPXE9pFrxGC+RWaWmVPAseY2c/c/VFCX/7xaBucAHw6Gg1+A7jSzF4F/g58390XZNX8OCFInopeD6cAR2WMirvicmBGtA1uJbzRT2z7Lu26FthA+P08QdgBmbNtozetnwEzzczNbA5hR+7Hox75G0CDmf2bsA/jG8AjZvYizd8YbiPsk5od1T8/Y9lXCO2SWYQB0yyaevmteY/wO3wLWEJoe70UbaPTCa+b2EloGlspFBYdGdRKv7cz65lAaB9dFR3B8mngUneP5Y6sQmJmnwfWuPvM6E36L4RPZ7/o49I+1LSzUzZHSwg79maZWT3hcLXT+7akzcZs4DYzu4bQy/47zY+2kj6gEbmISMypRy4iEnMKchGRmOv1HnlVVU2XezkVFYNYtaozBx/0nkKtTXV1XqHWpro6p1Drgq7VVllZ3up3AGI1Ii8p6e4hsD2nUGtTXZ1XqLWprs4p1Log/7XFKshFRCSXglxEJOYU5CIiMacgFxGJOQW5iEjMKchFRGJOQS4iEnOb7aRZj/xrIe8sXdN4uSgBh+81lolbZ8/nD++tWMf9z8ynviHF0LL+fOFj21NS3Dfvcfc/M5/FH6xt/4YdVFpaQl1dS2d/6xlFRQk+sfdYJowe0v6NO2FTfZJ7nnybNes25nW9LentbdZRqqtzCq2uRAIOnbINNjZ7Kvru2yyDvHZDPX/6+zs51zckU3z5MzlnpeLvry7l32990Hh5qo1gx3H539jtWblmA/c/M7/9Gxa4ogSc+z+75HWdcxat4ulXl+Z1nSK9beyIMgV5Ry3+IJwq8tAp23DMtAkAXHHHv1i0rOWR7qL3a0gk4KTDjd886ixaVtMnQZ6u76j9xnP4nmPyss7hw8tYvjx/I/z2XHbr861u5+5Y+H74nZ519E5M3nbLvK8/U29vs45SXZ1TaHUVJWDQgO6cua91sQvyOSvf5tEFT3H2rqcwsKSlM6jBwihItt16CGUDw4YbO7KM2fNWsnb9psbrAJKpFIs+WMvoLQezUxTeC5fV5K60F6Qfd2JG3d1VPqg/G/K0ro4YO7IMX1TNho31DOifv5fXomjbTNpmi7xtm9b09jbrKNXVOYVaV0+I3c7Od6rn89/qd1i0Zkmrt0mP3saNLG+8Lv3zoqyQrlq1ng0bGxg3sozKioEM6F/cIyPKjkjXlll33IwdWU4K8trnh/AmVzawH8OGlOZ1vSKbg9gF+ZDSsBNt9cY1rd5m0Qc1lPYrZuSwphPKNwV584BJj4LHjiynKJFg7Igy3luxjrpNHTrxel4tXFbD0MH9GVoW37BqbTt3R+2GTVRVb2DsyDISiY6eBF7kwyN2QT60fwiK1XUtB/nGTQ28t7yWMSPLKMr4ox87Ktwvu22yMGsUPHZUOakULMnziLI9NbUbWbmmjnGj4jsah4zt/H7+2lPpN4U4f1IR6UnxC/J2RuRLqtaRTKVy/ugrhw5gYGlJTmslHRJjR5YBTWHR233ypjriHVajhw2if0lRznbujsaWU8zf5ER6SmyDfE1dy0HR1Copa3Z9IpFg3Mgy3l9Ry4aN4djSVCrFwvdrqNxiQOPe5NZ66T2tqT9e1s4tC1tRUYIxI8pYunwdm+qTeVlnZvtLRHLFLsjL+5WRIEF1K62VlnZ0pmXviFtVU8fa9Zua3Xb08EH0Kyli4fu921rJbvHE2dhR5TQkUyzN06FfC5etpbR/MSMqBuZlfSKbm9gdflhcVExZ/8GsaaW1smhZDSXFCbYaPjhnWTokb3/wTcoG9mPDxrBDM3OkV1xUxDaVg1n4/lqunP5ih+sq6VdMfTd2kL63opbBA0rYcmjLh1TGSXo73/rXNxg0oOWXWGe213vL1zFxm6HN9nmISJPYBTnAFv2HsKy2ilQq1ewohvqGJEuq1rJ1ZVmLX7HfcXwFWw4pZU3tRtbUhq96Dxncn123a/4Fk312GsW7K+bx7op1Ha4pkUiQSnX5dKThcXcevVkclbHz+GFUlJdSva6O6nV1Ld6mM9urf/9i9t5pZD5LFNmsxDLIh5YOYfHad9nQsIGBJU0ft99bUUt9Q6rVPvMWZaX87/n7t7v+w/Ycw2Gd/GZlZWU5VVV980WiQrPl0AHc8KW2t7O2l0j+xK5HDjCkf3TkStYOz7b64yIim6t2R+RmVgTcAuwG1AFnuvvcjOUnAhcBDcBd7v6LHqq1UeMhiHVrGDV4ROP1jUc36DA1EfkQ6ciI/FhggLvvC1wG3JC1/HrgUGB/4CIz6/HZpoaWRl8KytrhuWhZmPxqm8p4H8InItIZHQnyacDfANz9BWBq1vLXgaHAACABdG+PXwcM7d80Ik9LT3611ZaDKe1X3NMliIgUjI7s7BwCrM643GBmJe6enrF9NvAysA64z92r21pZRcUgSkq6HrSVleWMKxoFs2BTcR2VlWF0vrRqLXUbG9h+XEXjdb2trx63Paqr8wq1NtXVOYVaF+S3to4E+Rog8xGL0iFuZrsCnwQmAGuB35rZZ939T62tbNWq2i4Xmz7SIVUXyn6/ennjkQ+vvrkMgFFDB/TJ0RCFehSG6uq8Qq1NdXVOodYFXautreDvSGvlWeBIADPbB5iVsWw1sB5Y7+4NwAdAj/fI09/uzOyRaz4OEfmw6siIfAZwmJk9R+iBn2ZmJwBl7v5LM7sNeMbMNgLvANN7rFpg9rwVPPjcAgaPG0x13Rpu/OcfeGfVYjZ6aN2PGaEgF5EPl3aD3N2TwLlZV8/JWH4rcGue62rV7PkreXvJarYeO4jl6z9gOSugDCpGbmDnERNa/Uq4iMjmKnapl4y+1p2oD3OSpFIJEokUhx40kMPG7dCXpYmI9InYBXkqmhk1tW4LSss/YM1bO1NqL+Or5nLYuIMBqGvYyK/f/COLa5pOB5dIFHHMtkcwZeTufVC1iEjPid1X9NMj8pr54/hE2RkkV1cytHgY71TPpz5ZT0OygTtm/YbXqmaxsWETyVSKZCrF8vUrePbdf/dx9SIi+Re/EXkU5GtqNzF7XjhkfeIW2/HyihdZsGYxzyz9F2+udHbZcgfOnnwKxUXhmPUrX7iehWsWk0wlKUrE7v1LRKRVsUu0ZMbUp7Pnr6BfSRG7jzIAfvvWvby47BUmDBnLGbuc1BjiABOGjGVDQx3vr/ug12sWEelJ8QvyjLOHpVJhXhUbNpEECarWr2DLARWcs+up9C/u3+x+E4aOBWD+moW9Wa6ISI+LX5BnnYxg3KhyBvcbxISh4xhQXMq5u55Gef/cSbMmDB0HwILVi3qlThGR3hLbHnlRIkEylWo8yfJ5u57KpmR94xS32UYPHkn/4v7MX5Mb5BvqN/Ba1Wwakg0MKS1n8vCdeu4JiIjkWeyCPBkNyLcaPpglVWsbTyIxqN+gNu9XlChifPkY3q6ex/r69c3OLPTkon8wc8ETjZcv2/NCxpRvlf/iRUR6QPxaK1GSH7XfOI7Ya0ynzgY0fuhYUqR4Y/mcZlPgzq2eT4IEB269b3R5Xn6LFhHpQfEL8qi1ssO4Co4/ZHuKijp+suIJQ8IOz1+9eQ+XP3s1L77/Kg3JBhasWcTowSM5ZMyBAMxfrR2iIhIfsQvy9L7Ooi6cbX6nLY2PjTmQPUd+BIAXl73K0nXvsTG5iQlDxzF84DDK+5UxT0EuIjESvx55smlnZ2eVFJXw6e2PAuDdde/hK99m26HjAdh26DgSiQTbDh3Hf5a/waoN1VQM2CJvdYuI9JT4BXl60qzO53gzuw3fmZlr3+OpRf8AQpBDOEzxP8vfYN7qBUwZ0PvzsixYs4j31i7L2/rKawZQU7Mhb+trT3FRMZOH79hsZ3I+pFIp5qx8m+q61e3fuJt6e5t1lOrqnEKrK5FIsNOWxpD++Z9qO7ZB3pneeEt2rdyZmQueYF19LWX9BlM5cDgA220xHoB5qxf2+gRbs5e/xa2vTyfV86c97VFjy7fh6x85j37F/fK2zicX/4MZcx/O2/pE+sIhYw7gM9sfnff1xi7Iu9Mjz7RN2VZUlG7Bqrpqth06nkS0vjFlW1OSKO71PvkHtcuZ/uY9FBcV8+mJR1Ga9c3Uriov791Ryazlb/Fa1Sz+4DM4acfPNm7X7piz8m3+OncmQ/sP4ehtj8jLOtvS29uso1RX5xRaXQnCiLwnxC7IG3vk3dxNm0gk2K1yZ55e8mxjWwWgX3E/xpRvw/w1C/nq37/ZmRU2vct0QUMqSYoUJ+94PHuPntLl9WTr7fMWThmxGz9+ZRUvvP8SLy57lVYjtxPbqyGa6OysyV9s/IZuTyrUcz2qrs4p1Lp6QuyCPNXYI+/+qOyjY6ZRXbeaPUft0ez6Q8ceyJOL/9H4WB1R0q+Y+k0N3apnjxG75jXE+0K/4n6cPflk7v3v/dRsbP2PqDPbK5Eo4pAxB/RKiIvEUeyCvDtHrWQbPnBLzpp8cs71u4+YzO4jJndqXR+md//2VAzYgnN2PaXN22h7ieRP7I4jT5KfEBcR2VzELshTyVS3++MiIpuT2EViMpXq8aMWRETiJH5BnlRrRUQkU+yCPJVSa0VEJFPsIjGZSmlELiKSIYZBnp9jyEVENhfxC/Jkim5OsyIislmJX5CnUiSU5CIijWIX5Cn1yEVEmoldkIfDD/u6ChGRwhG/INcXgkREmollkHf3pBIiIpuT2AV5KqVvdoqIZIpdkCeTqW6fr1NEZHMSuyBPqbUiItJM7IJcX9EXEWkuhkGuHrmISKbYBXlKPXIRkWbaPWenmRUBtwC7AXXAme4+N2P5nsCPgQTwPnCSu2/omXJ1+KGISLaOjMiPBQa4+77AZcAN6QVmlgBuB05z92nA34AePdW5TiwhItJcuyNyIB3QuPsLZjY1Y9kkYAXwNTPbBXjY3b2tlVVUDKKkpLir9ZIiRWlpCZWV5V1eR08pxJpAdXVFodamujqnUOuC/NbWkSAfAqzOuNxgZiXuXg8MB/YDLgDmAg+Z2Uvu/lRrK1u1qrbLxQ4fXkYqBfWbGqiqqunyenpCZWV5wdUEqqsrCrU21dU5hVoXdK22toK/I62VNUDmGoqiEIcwGp/r7m+5+ybCyH1q9gryJZlMhQLUIxcRadSRIH8WOBLAzPYBZmUsmweUmdnE6PIBwBt5rTBDMhUFuXJcRKRRR1orM4DDzOw5wpEpp5nZCUCZu//SzM4Afh/t+HzO3R/uqWKjAblOLCEikqHdIHf3JHBu1tVzMpY/BeyV57pa1Nha0VErIiKNYvWFIAW5iEiueAV51CNXjouINIlXkOuoFRGRHPEK8sYRuYJcRCQtXkGe1OGHIiLZYhbk4X+1VkREmsQqyFMpHbUiIpItVkGuo1ZERHLFK8h1HLmISI5YBXmDDj8UEckRqyBXj1xEJFesgrxx0izluIhIo3gFuXrkIiI54hnk6pGLiDSKV5CrRy4ikiOWQa4cFxFpEq8gV2tFRCRHLINcsx+KiDSJVZBHnRXNfigikiFWQa7WiohIrlgFeYNOLCEikiNWQa4TS4iI5IpVkDfOtaIkFxFpFKsg11f0RURyxSvI1SMXEckRryBPn7NTOS4i0iheQa4euYhIjngFuXrkIiI54hXkmjRLRCRHvIJcI3IRkRyxCnIdRy4ikitWQd7QeNSKglxEJC1WQa4euYhIrngFuWY/FBHJEasgT+mcnSIiOWIV5DpDkIhIrngFeUrT2IqIZCtp7wZmVgTcAuwG1AFnuvvcFm73S2Clu1+W9yojjSNyJbmISKOOjMiPBQa4+77AZcAN2Tcws3OAyXmuLUey8ZydCnIRkbSOBPk04G8A7v4CMDVzoZntB+wN3Jb36rI0HbXS048kIhIf7bZWgCHA6ozLDWZW4u71ZjYa+C7wKeBzHXnAiopBlJQUd75SIJl6N6xji0FUVpZ3aR09qRBrAtXVFYVam+rqnEKtC/JbW0eCfA2Q+YhF7l4f/fxZYDgwExgFDDKzOe4+vbWVrVpV28VSm0bka9ZsoKqqpsvr6QmVleUFVxOorq4o1NpUV+cUal3QtdraCv6OBPmzwNHAvWa2DzArvcDdbwJuAjCzU4Ed2grx7tLJl0VEcnUkyGcAh5nZc0ACOM3MTgDK3P2XPVpdFp1YQkQkV7tB7u5J4Nysq+e0cLvpeaqpVfpCkIhIrlgd/6HDD0VEcsUryHX4oYhIjlhFoibNEhHJFasgV49cRCRXrIK8QZNmiYjkiFWQ68QSIiK5YhXkKR21IiKSI1ZB3tQj7+NCREQKSLyCXEetiIjkiFeQq0cuIpIjXkGe0uGHIiLZ4hXkmv1QRCRHvII8pXN2iohki1eQJ7WzU0QkW6yCXMeRi4jkilWQN+g4chGRHLEKcp0hSEQkV7yCXD1yEZEcsQryxvnIY1W1iEjPilUkJpPhf30hSESkSbyCXHOtiIjkiFeQJ1MKcRGRLPEK8lRK/XERkSyxisVkMqX+uIhIlngFeUqtFRGRbPEK8qRaKyIi2WIVi6mUjlgREckWqyBvUI9cRCRHrII8HH7Y11WIiBSWeAV5KqWTSoiIZIlVkKd01IqISI5YBblaKyIiuWIX5NrZKSLSXLyCPJXSSSVERLLELMh1HLmISLZ4BXkypfN1iohkiV2Qq7UiItJcvIJchx+KiOQoae8GZlYE3ALsBtQBZ7r73IzlXwAuBOqBWcD57p7siWJ1HLmISK6OjMiPBQa4+77AZcAN6QVmNhC4Gviou+8PDAWO6olCARqSqEcuIpKl3RE5MA34G4C7v2BmUzOW1QH7uXttxvo2tLWyiopBlJQUd6VWkskUpf1LqKws79L9e5rq6pxCrQsKtzbV1TmFWhfkt7aOBPkQYHXG5QYzK3H3+qiFsgzAzL4MlAGPt7WyVatq21rcpmQqRUNDkqqqmi6vo6dUVparrk4o1LqgcGtTXZ1TqHVB12prK/g7EuRrgMw1FLl7ffpC1EP/ETAJ+Iy7pzpVXSeEHnlPrV1EJJ460iN/FjgSwMz2IezQzHQbMAA4NqPFknepVIpUCn1FX0QkS0dG5DOAw8zsOSABnGZmJxDaKC8BZwD/BJ4yM4CfuvuMfBeaTIWBvo4jFxFprt0gj/rg52ZdPSfj5145Fj0ZHdCoHBcRaS42XwhKRSNynVhCRKS52AR5Y2tFPXIRkWbiE+SNrRUFuYhIpvgEebq1ohwXEWkmNkGe0lErIiItik2QJ6OvGek4chGR5uIT5Mn0zs4+LkREpMDEJsjVWhERaVlsgrxpRK4gFxHJFJ8gj/5XjouINBebIE9pRC4i0qLYBLkmzRIRaVl8glwjchGRFsUmyKMBuYJcRCRLbIJcX9EXEWlZ7IJcPXIRkebiE+Sa/VBEpEWxCfKmE0v0cSEiIgUmNrGoE0uIiLQsPkGeTO/sVJCLSN857rijqaur4wc/+B4vvPBcX5cDdODky4Ui2Xj4Yd/WISLdc+9Tc3lxzgd5XeeeO4zgc4dMzOs64yQ2Qa7ZD0Wkq2bOfJCHH36AZDLJcccdz7333kNRURG77ro75533ZVatWsUPfvBd1q5dSyqV4oorvk9paSnXX38dGzfWsWLFcs4663wOPPDgvn4qLYpNkDcdR64gF4mzzx0ysU9Gz+Xl5Vx++Xc5//wzueOO3zBgwACuuurbvPjiCzz77DNMm3Ygxx57HLNm/Ye33nr7K3voAAANZElEQVSDiophfP7zJ/KRj0xl1qz/cOedtynIu6vp8MO+rUNE4mns2HEsWbKY6upVXHzxVwCora1l6dIlLFq0kE9+8hgAJk/ejcmTd2PevHe4++47efjh+4EE9fX1fVh92+IT5GqtiEg3JBJFjB69NSNGjOQnP7mFkpISZs58kO23n8SiRQuZM+dNtt9+Eq+99grPPfcMS5Ys5uijj2Xffffn4Ycf4JFHHurrp9Cq2AR5Socfikg3VVRUcPzxJ3LBBWfT0NDA6NFbccghh/HFL57OtddeyaOPziSRSHDZZd/mzTdn8/Of/5Tf/nY6lZUjqK6u7uvyW5VIB2Rvqaqq6dIDvuxV/HzGLD7/se05fM8x+S6r2yory6mqqunrMnKors4r1NpUV+cUal3QtdoqK8tbHcXG5jjyphF5HxciIlJgYhPk6pGLiLQsfkGuHrmISDOxCfJUdPihclxEpLnYBLlG5CIiLYtPkCfVIxcRaUlsgjx9zKJG5CLSly6//JJWl/3mN9N5883ZvVhNEJsvBDVNY9vHhYhIt9w39yFe/WBWXte5x4jJfHriUXldZ2uuueZ/W132xS+e2is1ZItPkOvwQxHpopkzH+Sf/3ya2tpaqqurOe20M7nzztsYM2Yc/fqVcMkl3+K6665k9erVAFx44SVst91EHnror8yY8ReSyQamTTuIM844h2OOOYIHHniU++77E4888hBFRUXsuONOXHjhJfzgB9/jYx87nKlT9+Kaa77Pu+8upaGhgc9//kQ+9rHDueCCs9l+e2PJkgVUV6/mqqt+yKhRo7v9/OIT5Ent7BTZHHx64lG9NnrOtH79em688edUV6/irLNOIZlMcuqpZzBp0g7ccstNTJmyF5/61HEsXryIa675Ptdc87/89rd3c/fd99C/fym33noztbW1jeubOfNBLrroUnbccWdmzPhzs0m17r//L2yxxRZ85ztXUVu7jtNPP4kpU/YCYMcdd+bqq7/H1Vdfx+OPP5qXUXy7QW5mRcAtwG5AHXCmu8/NWH408B2gHrjL3W/vdlUtSM8koGlsRaQrdt/9IxQVFTFs2JaUlw9h4cL5jB07HoB58+byyisv8eSTjwFQU7OGpUuXMmHCdpSWDgDgvPO+3Gx9l1/+He6557e8995P2Xnnyc2WLViwgKlTQ3APGjSY8eMnsHTpEgAmTTIARo4cyYoVK/Ly3Dqys/NYYIC77wtcBtyQXmBm/YAbgcOBg4CzzWxkXirLktRX9EWkG9znALBy5QrWrVtHRcWwxoHhuHHj+dznTuDmm3/JVVddx+GHf4Ktt96GRYsWsHHjRgCuuOIbVFU1ndnogQf+ysUXf5Obb/4lb7/tzJr1n8Zl48eP5/XXXwWgtnYd77zzDltttRXQM4PRjrRWpgF/A3D3F8xsasayHYG57r4KwMyeAQ4E/pTvQhtH5EpyEemClStX8NWvnsfatWu56KJLuf76axuXnXzy6Vx33VU88MB9USvkbCoqKjjxxFO44IKzSSQS7L//AVRWjmi8z3bbTeRLXzqLQYMGUVlZyU477cLMmQ8CcMwxn+aHP7ya8847g7q6Ok4//SwqKob12HNrd/ZDM7sD+Iu7PxJdXgRs6+71ZjYN+LK7Hx8tuxJY5O53tLa++vqGVElJcacLXbyshnuf+C9nf2oy5YP6d/r+IvLhdd999zFv3jwuvvjivi6lO1odxXZkRL4GKM+4XOTu9a0sKwfanLR31aratha3akARXHTiFKqqatiwrq5L6+hJhTplpurqvEKtTXV1TmZdNTUbqK3dWDB1dnEa21aXdSTInwWOBu41s32AzANA3wK2N7NhwFpCW+X6TlUnItLDjjzy6L4uoUd1JMhnAIeZ2XOEof1pZnYCUObuvzSzrwOPEnac3uXuS3uuXBERydZukLt7Ejg36+o5GcsfBB7Mc10iItJBsZlrRUREWqYgFxGJOQW5iEjMKchFRGJOQS4iEnPtfrNTREQKm0bkIiIxpyAXEYk5BbmISMwpyEVEYk5BLiIScwpyEZGYU5CLiMRcR6ax7XPtnQC6l2vpB9wFjAdKgauBN4HpQAqYDXwpmjWyL+obAbwMHEY4IXah1PVN4BigP+F3+X99XVv0u7yb8LtsAM6iALaZme0N/NDdDzaziS3VY2ZnAedE9V7t7g/1cl27Az8jbLc64GR3X9bXdWVcdwLh7GX7Rpf7enuNAG4HKoBiwvZ6J191xWVE3uoJoPvAScAKdz8A+DhwM/Bj4IrougTwP31RWBRMtwHro6sKpa6Dgf2A/Qkn6R5TILUdCZS4+37AlcAP+rouM/sGcAcwILoqpx4zGwV8hbA9jwCuNbPSXq7rp4SgPBi4D7i0QOrCzPYAziA6NVqB1PUj4HfufiBwBbBDPuuKS5A3OwE0MLXtm/eoPwHfjn5OEN5JpxBGmACPAIf2QV0Qzs50K/BudLlQ6jqCcGapGYS56x+iMGr7L1ASfeIbAmwqgLreAT6dcbmlevYCnnX3OndfDcwFdu3luj7v7q9FP5cAGwqhLjPbErgGuDDjNn1eFyGstzGzJ4ATgafzWVdcgnwIsDrjcoOZ9UlbyN3XunuNmZUDfya8uybcPT3XQQ0wtLfrMrNTgSp3fzTj6j6vKzKc8Ob7WcJJSn5HOPdrX9e2ltBWmUP42HsTfbzN3P0vhDeUtJbqyf576PE6s+ty9/cAzGw/4ALgxr6uy8yKgTuBr0ePndbn24vwOlvl7ocCi4BL81lXXIK8rRNA9zozGwP8HfiNu/8eyOyhtnsC6h5yOuGUfE8DuwO/BkYUQF0AK4BH3X2juzth9Jb5gu2r2r4W1TWJsP/lbkIPv6/rytTSa6vTJz3vCWZ2POET4CfdvaoA6poCbA/8AvgDsJOZ/aQA6oLwN/BA9PODhIFN3uqKS5A/S+hn0sIJoHuVmY0EHgMudfe7oqtfjfrAAJ8A/tnbdbn7ge5+UNSzfA04GXikr+uKPAN83MwSZrYVMBh4sgBqW0XTiGgl0I8C+F1maamefwMHmNkAMxsK7EjYEdprzOwkwkj8YHefF13dp3W5+7/dfefob+DzwJvufmFf1xV5hijDCCepfyOfdcXiqBVaOAF0H9ZyOWHP87fNLN0r/ypwk5n1B94itFwKwUXA7X1dl7s/ZGYHEl64RcCXgPkFUNuNwF1m9k/CSPxy4KUCqCtTzu/Q3RvM7CZCqBcB33L3Db1VUNTCuInQIrjPzAD+z92/25d1tcbd3y+Aui4C7jCz8wiDhxPcfVW+6tI0tiIiMReX1oqIiLRCQS4iEnMKchGRmFOQi4jEnIJcRCTmFOTSa8zscTP7VMbl681sbXRoXfq6d81sQhvruMPMWp2iwczGm9mCVpb9yszGRT/PjI5p7xYzS5nZa9G//5jZQjO7LTpEr637NdYi0l1xOY5cNg9PEibPmhFdPhR4gTCXzlPRTH/r3H1+aytw9zO78fgfBb4frefIdm7bYe6+e/pnMxtC+FLH4YS5UdqtRaS7FOTSm54CfgJgZlsTpj/9E2FSraeAA4DHo+V7Er6wMwhYDpzj7vOjKQi+5+5Pm9m1wHHR8vcIX4F+GhhoZn8AdiF8e/NYwhS1WwEzzewAwlS/B0f/Pg4MA7YFHnP386Mactbv7tPbeY7Do5pXRuv4AfCxaP3LCRMpnZpVy7atPNevA6cQvqb/b3c/pwPbWD6E1FqR3vQysJ2ZDSCMWB+L/h0RLT8QeCxqtdxB+PbbRwjTFt+euSIzO5owkt+Z8NXnPTIWVwI/dvddgGWEmfquI8wKeaS7r8iqaz/gM4SZ5442s8ntrL+ZqK3yhplVEeYO/4q7/yv6hLEDsF80n8tc4MTMWggTJeU812hSuG8S5uSYAiSjNz+RHApy6TXu3kBopUwlhPdjURtlkJlVAPsSJiObBGwHPGBmrwE/JIxaMx0G3BtNxLUK+GvGsnfd/d/Rz28QRsltec7da9y9FphHGD23tf7s57W7u+9MmD61Ang4un4u4avZZ5rZDdHzK8u6e4vPNZoU7jngReC7wM/dfWk7z0M+pBTk0tueJMzNvBfwfHTdE4QTOKyI5mUuBuZFAbk7YUQ6LWs9DbT++s2cGTNFdIKBNmTOb5G+fVvrb5G730gYaf8IwMymED5xFBHmbJnRQi1tPddjgfOi+/zNzA7qTD3y4aEgl972FGFmxlkZUxE/Thi5Ph5dngMMi/rHEKbo/X3Weh4HPmNm/aMdjEcRQrgt9XR8v1BX1g9hLuzTzGxXwtmQnnb3WwmnAzycENyZtbT4XM2skjBJ1ix3/w7hDaGnT4YgMaUgl17l7rOBLQnBlPYUoZf8WHSbOsJJKG4ws9cJO/zOyFrPTOAfwKuEVsa7NJ3irjUPEXYwtnp4YzfXj7u/QZjX/Abgj8Bu0XN4CngdSD/2Q8BMwk7PnOcaze99G/Cimb1MaNlMb+/x5cNJsx9KLJnZvsAkd7/bwrlKnwdOd/fX47B+kXxSkEssmdkwQrtlNOGT5d3ufn1c1i+STwpyEZGYU49cRCTmFOQiIjGnIBcRiTkFuYhIzCnIRURi7v8B41AfXLqyLHsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204384293c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(plotdata[\"weight\"], plotdata[\"recall\"])\n",
    "plt.plot(plotdata[\"weight\"], plotdata[\"precision\"])\n",
    "plt.title(\"Different Oversampling Rates of Failing Students\")\n",
    "plt.xlabel(\"Weighting Rates\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
